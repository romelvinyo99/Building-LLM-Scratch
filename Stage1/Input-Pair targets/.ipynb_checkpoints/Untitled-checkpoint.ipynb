{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e64178-3b71-4b31-afa6-926eef99779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of contents in our text file: \n",
      " I HAD always thought Jack Gisbur\n",
      "\n",
      "Length of charachters in our raw text file = 20479 charachters\n"
     ]
    }
   ],
   "source": [
    "# Reading the text file\n",
    "\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf=8\") as f:\n",
    "    raw_text = f.read()\n",
    "print(f\"Example of contents in our text file: \\n {raw_text[:32]}\\n\")    \n",
    "print(f\"Length of charachters in our raw text file = {len(raw_text)} charachters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dcb98e4-b1f3-4f0b-bfbe-5e1f86af702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Encoding 'gpt2'>\n"
     ]
    }
   ],
   "source": [
    "# Byte pair tokenization\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af6915a4-6d63-42f9-ae0a-158d97d71144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding the text\n",
    "\n",
    "token_ids = tokenizer.encode(raw_text)\n",
    "len(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f272e12-cf72-443d-9d61-c6ac8ea4bd5f",
   "metadata": {},
   "source": [
    "## Input-Pair Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d86a48-9d01-4266-aaaf-1f26b5ac14d0",
   "metadata": {},
   "source": [
    "- For each text chunk, we want the inputs and targets\n",
    "- Since we want the model to predict the next word, the targets are the inputs shifted by one position to the right\n",
    "- context size = How many tokens are included in the input\n",
    "- Example:\n",
    "   - X = [1, 2, 3, 4]\n",
    "   - y = [5, 6, 7, 8]\n",
    "     - If X = [1]          y = 5\n",
    "     - If X = [1, 2]       y = 6\n",
    "     - If X = [1, 2, 3]    y = 7\n",
    "     - If X = [1, 2, 3, 4] y = 8\n",
    "   - context size = 4       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53633366-e8ef-4a61-96a2-783500a8ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sample by removing the first 50 tokens\n",
    "\n",
    "sample_tokens = token_ids[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b66f2250-0e96-4b0f-8f08-3cc6f20f52f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) = [290, 4920, 2241, 287]\n",
      "f(y) =      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "# Example of the technique for creating input-pair tokens\n",
    "\n",
    "context_size = 4\n",
    "# This means the model is trained to look at a sequence of 4 tokens to predict the next word\n",
    "# For example if x is the first 4 tokens = [1, 2, 3, 4] y next 4 tokens = [2, 3, 4, 5]\n",
    "X = sample_tokens[:context_size]\n",
    "y = sample_tokens[1:context_size+1]\n",
    "print(f\"f(x) = {X}\")\n",
    "print(f\"f(y) =      {y}\")\n",
    "# Checking the condions\n",
    "# x = [290]                  : y = 4920\n",
    "# X = [290, 4920]            : y = [2241]\n",
    "# X = [290, 4920, 2241]      : y = [287]\n",
    "# X = [290, 4920, 2241, 287] : y = [257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1d2bb66-e77b-47b5-a88c-53b25c148fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290]  ---> 4920\n",
      "[290, 4920]  ---> 2241\n",
      "[290, 4920, 2241]  ---> 287\n",
      "[290, 4920, 2241, 287]  ---> 257\n"
     ]
    }
   ],
   "source": [
    "# Processing the inputs along with the targets where inputs are shifted one position to the right to create next-word prediction task\n",
    "\n",
    "for i in range(1, context_size+1):\n",
    "    # Input\n",
    "    context = sample_tokens[:i]\n",
    "    # Target\n",
    "    desired = sample_tokens[i]\n",
    "    print(f\"{context}  ---> {desired}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b0db9-a926-4f45-9fe9-8f9acdf0519a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
